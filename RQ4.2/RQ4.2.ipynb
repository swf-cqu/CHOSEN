{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "import json\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import recall_score\r\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "def splitFromFile(category_name, sample_type):\r\n",
    "    ''' Get the Features and label from the JSON file\r\n",
    "\r\n",
    "    :param category_name: The path of Train or Test\r\n",
    "    :param sample_type: The concrete content of file\r\n",
    "    :return: data[] and target[]\r\n",
    "    '''\r\n",
    "\r\n",
    "    target = []\r\n",
    "    data = []\r\n",
    "    category_name=os.path.join(category_name,sample_type)\r\n",
    "    file_list = os.listdir(category_name)\r\n",
    "    file_list = sorted(file_list, key=lambda x: int(x[0:x.index('.')]))\r\n",
    "    for _ in file_list:\r\n",
    "        with open(os.path.join(category_name,_), encoding='UTF-8') as fp:\r\n",
    "            dic = json.load(fp)  # The size of content is only a line\r\n",
    "            a = [\r\n",
    "                  dic[\"add_annotation_line\"]\r\n",
    "                , dic[\"add_call_line\"]\r\n",
    "                , dic[\"add_classname_line\"]\r\n",
    "                , dic[\"add_condition_line\"]\r\n",
    "                , dic[\"add_field_line\"]\r\n",
    "                , dic[\"add_import_line\"]\r\n",
    "                , dic[\"add_packageid_line\"]\r\n",
    "                , dic[\"add_parameter_line\"]\r\n",
    "                , dic[\"add_return_line\"]\r\n",
    "                , dic[\"del_annotation_line\"]\r\n",
    "                , dic[\"del_call_line\"]\r\n",
    "                , dic[\"del_classname_line\"]\r\n",
    "                , dic[\"del_condition_line\"]\r\n",
    "                , dic[\"del_field_line\"]\r\n",
    "                , dic[\"del_import_line\"]\r\n",
    "                , dic[\"del_packageid_line\"]\r\n",
    "                , dic[\"del_parameter_line\"]\r\n",
    "                , dic[\"del_return_line\"]\r\n",
    "            ]\r\n",
    "            label = 0 if dic['label'] == \"NEGATIVE\" else 1\r\n",
    "            target.append(label)\r\n",
    "            data.append(a)\r\n",
    "            if sample_type==\"TestSample\" or sample_type==\"TestSample_Rule\":\r\n",
    "                if dic[\"true_label\"] is not None:\r\n",
    "                    target_true.append(0 if dic['true_label'] == \"NEGATIVE\" else 1)\r\n",
    "                else:\r\n",
    "                    raise Exception(\"The true_label is null\", _)\r\n",
    "    return data, target"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "def train(x_train,y_train):\r\n",
    "    #print(len(x_train), len(x_test))\r\n",
    "    model=RandomForestClassifier()\r\n",
    "    model.fit(x_train,y_train)\r\n",
    "    return model\r\n",
    "\r\n",
    "if __name__==\"__main__\":\r\n",
    "\r\n",
    "    '''\r\n",
    "    RQ4.1\r\n",
    "    '''\r\n",
    "    target_true=[]\r\n",
    "\r\n",
    "\r\n",
    "    #获得SITAR corrected training set , cleaned testing set\r\n",
    "    project_path=r\"E:\\Project_Code\\JustInTestPro\\Heuristic_Sample\\flink\"\r\n",
    "    x_train,y_train=splitFromFile(project_path,\"Train\")\r\n",
    "\r\n",
    "    try:\r\n",
    "        x_test,y_test=splitFromFile(project_path,\"TestSample\")\r\n",
    "    except Exception as ep:\r\n",
    "        print(ep.__repr__())\r\n",
    "\r\n",
    "    preprocessing.scale(x_train)\r\n",
    "    preprocessing.scale(x_test)\r\n",
    "    total_sum=0;\r\n",
    "    times=20\r\n",
    "    accuracyList1=[]\r\n",
    "    precisionList1=[]\r\n",
    "    recallList1=[]\r\n",
    "    accuracyList2=[]\r\n",
    "    precisionList2=[]\r\n",
    "    recallList2=[]\r\n",
    "    print(\"Only one UnderSample\")\r\n",
    "    for i in range(times):\r\n",
    "        print(\"The times of iterator is %d\" %(i+1))\r\n",
    "        from imblearn.under_sampling import RandomUnderSampler\r\n",
    "        rus = RandomUnderSampler()\r\n",
    "        x_train, y_train = rus.fit_resample(x_train, y_train)\r\n",
    "        model=train(x_train,y_train)\r\n",
    "        print(len(x_train))\r\n",
    "        y_pred=model.predict(x_test)\r\n",
    "        accuracyList1.append(accuracy_score(y_test, y_pred))\r\n",
    "        precisionList1.append(precision_score(y_test,y_pred))\r\n",
    "        recallList1.append(recall_score(y_test,y_pred))\r\n",
    "        accuracyList2.append(accuracy_score(target_true, y_pred))\r\n",
    "        precisionList2.append(precision_score(target_true,y_pred))\r\n",
    "        recallList2.append(recall_score(target_true,y_pred))\r\n",
    "    for i in zip(accuracyList2,precisionList2,recallList2):\r\n",
    "        print(\"The True Accuracy is {:.2%}; The True Precision is {:.2%}; The True Recall is {:.2%}\".format(\r\n",
    "            *i\r\n",
    "        ))\r\n",
    "    print(\"The average True Accuracy is {:.2%}; The True average Precision is {:.2%}; The True average Recall is {:.2%}\".format(\r\n",
    "        sum(accuracyList2)/times, sum(precisionList2)/times, sum(recallList2)/times)\r\n",
    "    )\r\n",
    "    print(len(target_true))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Only one UnderSample\n",
      "The times of iterator is 1\n",
      "10026\n",
      "The times of iterator is 2\n",
      "10026\n",
      "The times of iterator is 3\n",
      "10026\n",
      "The times of iterator is 4\n",
      "10026\n",
      "The times of iterator is 5\n",
      "10026\n",
      "The times of iterator is 6\n",
      "10026\n",
      "The times of iterator is 7\n",
      "10026\n",
      "The times of iterator is 8\n",
      "10026\n",
      "The times of iterator is 9\n",
      "10026\n",
      "The times of iterator is 10\n",
      "10026\n",
      "The times of iterator is 11\n",
      "10026\n",
      "The times of iterator is 12\n",
      "10026\n",
      "The times of iterator is 13\n",
      "10026\n",
      "The times of iterator is 14\n",
      "10026\n",
      "The times of iterator is 15\n",
      "10026\n",
      "The times of iterator is 16\n",
      "10026\n",
      "The times of iterator is 17\n",
      "10026\n",
      "The times of iterator is 18\n",
      "10026\n",
      "The times of iterator is 19\n",
      "10026\n",
      "The times of iterator is 20\n",
      "10026\n",
      "The Accuracy is 61.38%; The Precision is 80.00%; The Recall is 56.65%\n",
      "The Accuracy is 60.52%; The Precision is 80.38%; The Recall is 54.51%\n",
      "The Accuracy is 61.10%; The Precision is 81.41%; The Recall is 54.51%\n",
      "The Accuracy is 60.23%; The Precision is 79.50%; The Recall is 54.94%\n",
      "The Accuracy is 60.81%; The Precision is 79.75%; The Recall is 55.79%\n",
      "The Accuracy is 60.81%; The Precision is 80.12%; The Recall is 55.36%\n",
      "The Accuracy is 60.81%; The Precision is 80.12%; The Recall is 55.36%\n",
      "The Accuracy is 59.94%; The Precision is 78.66%; The Recall is 55.36%\n",
      "The Accuracy is 61.10%; The Precision is 79.88%; The Recall is 56.22%\n",
      "The Accuracy is 59.94%; The Precision is 79.01%; The Recall is 54.94%\n",
      "The Accuracy is 61.67%; The Precision is 80.12%; The Recall is 57.08%\n",
      "The Accuracy is 61.96%; The Precision is 81.37%; The Recall is 56.22%\n",
      "The Accuracy is 60.23%; The Precision is 79.50%; The Recall is 54.94%\n",
      "The Accuracy is 61.38%; The Precision is 80.00%; The Recall is 56.65%\n",
      "The Accuracy is 61.67%; The Precision is 79.76%; The Recall is 57.51%\n",
      "The Accuracy is 58.50%; The Precision is 77.99%; The Recall is 53.22%\n",
      "The Accuracy is 60.81%; The Precision is 80.50%; The Recall is 54.94%\n",
      "The Accuracy is 61.10%; The Precision is 79.88%; The Recall is 56.22%\n",
      "The Accuracy is 61.38%; The Precision is 80.37%; The Recall is 56.22%\n",
      "The Accuracy is 59.37%; The Precision is 78.40%; The Recall is 54.51%\n",
      "The True Accuracy is 68.01%; The True Precision is 71.52%; The True Recall is 64.84%\n",
      "The True Accuracy is 68.30%; The True Precision is 72.78%; The True Recall is 63.19%\n",
      "The True Accuracy is 67.72%; The True Precision is 72.44%; The True Recall is 62.09%\n",
      "The True Accuracy is 65.71%; The True Precision is 69.57%; The True Recall is 61.54%\n",
      "The True Accuracy is 68.01%; The True Precision is 71.78%; The True Recall is 64.29%\n",
      "The True Accuracy is 67.44%; The True Precision is 71.43%; The True Recall is 63.19%\n",
      "The True Accuracy is 68.01%; The True Precision is 72.05%; The True Recall is 63.74%\n",
      "The True Accuracy is 67.15%; The True Precision is 70.73%; The True Recall is 63.74%\n",
      "The True Accuracy is 67.15%; The True Precision is 70.73%; The True Recall is 63.74%\n",
      "The True Accuracy is 65.99%; The True Precision is 69.75%; The True Recall is 62.09%\n",
      "The True Accuracy is 68.30%; The True Precision is 71.69%; The True Recall is 65.38%\n",
      "The True Accuracy is 68.01%; The True Precision is 72.05%; The True Recall is 63.74%\n",
      "The True Accuracy is 66.28%; The True Precision is 70.19%; The True Recall is 62.09%\n",
      "The True Accuracy is 67.44%; The True Precision is 70.91%; The True Recall is 64.29%\n",
      "The True Accuracy is 68.30%; The True Precision is 71.43%; The True Recall is 65.93%\n",
      "The True Accuracy is 65.13%; The True Precision is 69.18%; The True Recall is 60.44%\n",
      "The True Accuracy is 68.01%; The True Precision is 72.33%; The True Recall is 63.19%\n",
      "The True Accuracy is 68.30%; The True Precision is 71.95%; The True Recall is 64.84%\n",
      "The True Accuracy is 66.86%; The True Precision is 70.55%; The True Recall is 63.19%\n",
      "The True Accuracy is 66.57%; The True Precision is 70.37%; The True Recall is 62.64%\n",
      "The average Accuracy is 60.73%; The average Precision is 79.84%; The average Recall is 55.56%\n",
      "The average True Accuracy is 67.33%; The True average Precision is 71.17%; The True average Recall is 63.41%\n",
      "347\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}